import random

class PromptTemplate:
    """
    A class for generating prompts to improve an initial model answer using one of the provided critique and revsion principles or to select the better of two generated model answers based on one of the provided comparison principles. The used prompt templates are based on the ones used in Constitutional AI approach by Anthropic.

    Attributes:
        user_prompt (str): The prompt for which the LLM answer will be improved.
        initial_answer (str): The initial answer generated by the LLM.
        critique (str): The critique of the initial answer.
        revision (str): The revised answer based on the critique.
        critique_principle (str): Specific request for critique generation.
        revision_principle (str): Specific request for revision generation.
        principles (dict): Constitutional principles for answer improvement and comparison.
    """

    def __init__(
        self,
        user_prompt,
        initial_answer=None,
        critique_principle=None,
        critique=None,
        revision_principle=None,
        revision=None,
        comparison_answer_1=None,
        comparison_answer_2=None,
        comparison_principle=None,
        chain_of_thought=None,
        selected_answer=None,
        principles=None
    ):
        """
        Initializes the PromptTemplate class with the provided arguments.

        Args:
            user_prompt (str): The prompt for which the LLM answer will be improved.
            initial_answer (str, optional): The initial answer. Defaults to None.
            critique_principle (str, optional): Specific request for critique generation. Defaults to None.
            critique (str, optional): The critique of the initial answer. Defaults to None.
            revision_principle (str, optional): Specific request for revision generation. Defaults to None.
            revision (str, optional): The revised answer. Defaults to None.
            comparison_answer_1 (str, optional): The first answer for comparison. Defaults to None.
            comparison_answer_2 (str, optional): The second answer for comparison. Defaults to None.
            comparison_principle (str, optional): Specific request for comparison generation. Defaults to None.
            chain_of_thought (str, optional): The generated chain of thought for the comparison. Defaults to None.
            selected_answer (str, optional): The selected answer from the comparison. Defaults to None.
            principles (dict, optional): Constitution instructions for generating prompts. Defaults to a default structure.
        """
        self.user_prompt = user_prompt
        self.initial_answer = initial_answer
        self.critique = critique
        self.revision = revision
        self.comparison_answer_1 = comparison_answer_1
        self.comparison_answer_2 = comparison_answer_2
        self.chain_of_thought = chain_of_thought
        self.selected_answer = selected_answer
        self.principles = principles or {
            "system_message_user_prompt": "",
            "system_message_critique": "",
            "system_message_revision": "",
            "critique_revision_principles": [],
            "critique_revision_few_shots": [],
            "comparison_principles": [],
            "comparison_few_shots": [],
        }

        if critique_principle or revision_principle or len(self.principles["critique_revision_principles"]) == 0:
            self.critique_principle = critique_principle
            self.revision_principle = revision_principle
        else:
            critique_revision_principle = random.choice(self.principles["critique_revision_principles"])
            self.critique_principle = critique_revision_principle["critique"]
            self.revision_principle = critique_revision_principle["revision"]

        if comparison_principle or len(self.principles["comparison_principles"]) == 0:
            self.comparison_principle = comparison_principle
        else:
            self.comparison_principle = random.choice(self.principles["comparison_principles"])

    def generate_system_prompt(self, message):
        """
        Generates a system prompt with the given message.

        Args:
            message (str): The message to be included in the system prompt.

        Returns:
            list: A list containing the system prompt.
        """
        return [{
            "role": "system",
            "content": message,
        }]

    def generate_system_prompt_initial_answer(self):
        return self.generate_system_prompt(self.principles["system_message_user_prompt"])
    
    def generate_system_prompt_critique(self):
        return self.generate_system_prompt(self.principles["system_message_critique"])
    
    def generate_system_prompt_revision(self):
        return self.generate_system_prompt(self.principles["system_message_revision"])

    def generate_initial_answer_prompt(self, include_system_prompt=True):
        input_prompt = [{
            "role": "user",
            "content": self.user_prompt,
        }]
        if include_system_prompt:
            return self.generate_system_prompt_initial_answer() + input_prompt
        else:
            return input_prompt
        
    def generate_few_shot_critique_prompt(self):
        few_shot_critique_prompt = []
        for example in self.principles["critique_revision_few_shots"]:
            # Format the conversation history as a single string
            conversation_history = f"Human: {example.get('input', '')}\n" + \
                                   f"Assistant: {example.get('initial_answer', '')}\n\n" + \
                                   f"---\nCritiqueRequest: {example.get('critique_principle', '')}"
            user_input = {
                "role": "user",
                "content": conversation_history
            }
            # Assistant's critique response
            assistant_critique = {
                "role": "assistant",
                "content": "Critique: " + example.get("critique", "")
            }
            few_shot_critique_prompt.extend([user_input, assistant_critique])
        return few_shot_critique_prompt

    def generate_critique_prompt(self):
        input_prompt = [{
            "role": "user",
            "content": f"Human: {self.user_prompt}\n"
                       f"Assistant: {self.initial_answer}\n\n"
                       f"---\nCritiqueRequest: {self.critique_principle}",
        }]
        # Combine prefix, few shot examples, and input
        return self.generate_system_prompt_critique() + self.generate_few_shot_critique_prompt() + input_prompt

    def generate_few_shot_revision_prompt(self):
        few_shot_revision_prompt = []
        for example in self.principles["critique_revision_few_shots"]:
            # Format the complete conversation history as a single string
            conversation_history = f"Human: {example.get('input', '')}\n" + \
                                   f"Assistant: {example.get('initial_answer', '')}\n" + \
                                   f"---\nCritiqueRequest: {example.get('critique_principle', '')}\n" + \
                                   f"Critique: {example.get('critique', '')}\n\n" + \
                                   f"---\nRevisionRequest: {example.get('revision_principle', '')}"
            user_input = {
                "role": "user",
                "content": conversation_history
            }
            # Assistant's revision response
            assistant_revision = {
                "role": "assistant",
                "content": "Revision: " + example.get("revision", "")
            }
            few_shot_revision_prompt.extend([user_input, assistant_revision])
        return few_shot_revision_prompt
    
    def generate_revision_prompt(self):
        input_prompt = [{
            "role": "user",
            "content": f"Human: {self.user_prompt}\n"
                       f"Assistant: {self.initial_answer}\n\n"
                       f"---\nCritiqueRequest: {self.critique_principle}"
                       f"Critique: {self.critique}\n\n"
                       f"---\nRevisionRequest: {self.revision_principle}",
        }]
        # Combine prefix, few shot examples, and input
        return self.generate_system_prompt_revision() + self.generate_few_shot_revision_prompt() + input_prompt

    def generate_few_shot_comparison_prompt(self):
        few_shot_comparison_prompt = []
        for example in self.principles["comparison_few_shots"]:
            # Format the conversation history as a single string
            single_shot_comparison_prompt = [
                {
                    "role": "user",
                    "content": f"{example.get('task', '')}"
                },
                {
                    "role": "assistant",
                    "content": f"{example.get('chain_of_thought', '')}"
                },
                {
                    "role": "user",
                    "content": f"{example.get('selected_answer', '')}"
                }
            ]
            few_shot_comparison_prompt.extend(single_shot_comparison_prompt)
        return few_shot_comparison_prompt
    
    def generate_chain_of_thought_comparison_prompt(self, include_system_prompt=False):
        input_prompt = [
            {
                "role": "user",
                "content": f"Consider the following conversation between a human (H) and an assistant (A):\n\nH: {self.user_prompt}\n\n{self.comparison_principle}\n(A)[[[{self.comparison_answer_1}]]]\n(B) [[[{self.comparison_answer_2}]]]"
            },
            {
                "role": "assistant",
                "content": f"Let's think step by step:\n"
            }
        ]
        # Combine system prompt (if applicable) few shot examples and input
        if include_system_prompt:
            return self.generate_system_prompt() + self.generate_few_shot_comparison_prompt() + input_prompt
        else:
            return self.generate_few_shot_comparison_prompt() + input_prompt
    
    def generate_selected_answer_comparison_prompt(self, include_system_prompt=False):
        input_prompt = [
            {
                "role": "user",
                "content": f"Consider the following conversation between a human (H) and an assistant (A):\n\nH: {self.user_prompt}\n\n{self.comparison_principle}\n(A)[[[{self.comparison_answer_1}]]]\n(B) [[[{self.comparison_answer_2}]]]"
            },
            {
                "role": "assistant",
                "content": f"Let's think step by step:\n{self.chain_of_thought}"
            },
            {
                "role": "user",
                "content": f"So the answer is: "
            },
        ]
        if include_system_prompt:
            return self.generate_system_prompt() + self.generate_few_shot_comparison_prompt() + input_prompt
        else:
            return self.generate_few_shot_comparison_prompt() + input_prompt

    def get_history(self):
        history = {
            "user_prompt": self.user_prompt,
            "initial_answer": self.initial_answer,
            "critique_principle": self.critique_principle,
            "critique": self.critique,
            "revision_principle": self.revision_principle,
            "revision": self.revision,
            "comparison_answer_1": self.comparison_answer_1,
            "comparison_answer_2": self.comparison_answer_2,
            "comparison_principle": self.comparison_principle,
            "chain_of_thought": self.chain_of_thought,
            "selected_answer": self.selected_answer,
        }
        return {k: v for k, v in history.items() if v}
